{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25d90ce4-15ca-4902-a7ec-9072d494a161",
   "metadata": {},
   "source": [
    "# üîπUFC Fight Predictor Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d449832-3e08-4907-93fb-119ddeccc9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ETA to scrape everything will roughly take 1hr.\n",
    "\"\"\"\n",
    "\n",
    "%pip install bs4 requests fake_useragent lxml pandas numpy urllib3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace07a8c-af2f-4579-9244-b690e31ced23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from fake_useragent import UserAgent\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import threading \n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505ffbd2-9668-453d-9a48-5d3e0011f402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "#           Thread Synchronization\n",
    "# ===========================================\n",
    "# The lock is used to prevent multiple threads from accessing and modifying\n",
    "# shared data structures simultaneously, which could lead to race conditions.\n",
    "lock = threading.Lock()\n",
    "\n",
    "# ===========================================\n",
    "#   Global Variables to Store Scraped Data\n",
    "# ===========================================\n",
    "# Each list will serve as a container for the scraped information.\n",
    "fight_details = []           # Detailed information about each fight\n",
    "new_fight_links_all = []     # Links to newly found fights\n",
    "winner_names = []            # Names of the fight winners\n",
    "fighter_detail_data = []     # Individual data for each fighter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d75764-7d3a-46a3-b3aa-8288cf4bcc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "#          Scraping Configuration\n",
    "# ===========================================\n",
    "\n",
    "# Maximum number of concurrent threads to use when scraping.\n",
    "# Increasing this value can speed up scraping but also increases the risk\n",
    "# of being blocked by the website. Recommended: 2‚Äì5 threads.\n",
    "MAX_THREADS = 3  \n",
    "\n",
    "# Generate a random Chrome User-Agent string to help avoid detection.\n",
    "# Using dynamic user agents reduces the chance of being flagged as a bot.\n",
    "ua = UserAgent()\n",
    "chrome = ua.chrome\n",
    "\n",
    "# HTTP headers for requests. Including a User-Agent is critical since\n",
    "# many websites block requests without it.\n",
    "HEADER = {\n",
    "    \"User-Agent\": chrome\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d1dc07-f83e-45d2-9b78-457258e8aec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_session():\n",
    "    \"\"\"\n",
    "    Create a requests.Session with a retry strategy for reliable scraping.\n",
    "\n",
    "    Returns:\n",
    "        session (requests.Session): Configured session object with retry logic.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize a session object\n",
    "    session = requests.Session()\n",
    "\n",
    "    # Define a retry strategy:\n",
    "    # - backoff_factor controls wait time between retries (exponential growth).\n",
    "    #   e.g., 1st retry waits 7s, 2nd waits 14s, 3rd waits 28s, etc.\n",
    "    # - total is the maximum number of retries.\n",
    "    # - status_forcelist specifies which HTTP error codes will trigger a retry.\n",
    "    # - allowed_methods defines which HTTP methods will be retried.\n",
    "    retry_strategy = Retry(\n",
    "        total=10, \n",
    "        backoff_factor=7,\n",
    "        status_forcelist=[429, 500, 502, 503, 504],\n",
    "        allowed_methods=[\"GET\"]\n",
    "    )\n",
    "\n",
    "    # Attach the retry strategy to both HTTP and HTTPS adapters\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "    session.mount(\"https://\", adapter)\n",
    "    session.mount(\"http://\", adapter)\n",
    "\n",
    "    return session\n",
    "\n",
    "# Create the global session instance to use across all requests\n",
    "session = create_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ebea3d-baa5-45a7-aa3b-b1d1e68f7409",
   "metadata": {},
   "source": [
    "# Scrapping the event links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cb8dc3-547f-4f2c-8d72-eb90721e7687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "#     Scrape UFC Completed Events Page\n",
    "# ===========================================\n",
    "\n",
    "# URL listing all completed UFC events\n",
    "ufc_link = \"http://ufcstats.com/statistics/events/completed?page=all\"\n",
    "\n",
    "# Send the HTTP GET request using the preconfigured session\n",
    "response = session.get(ufc_link, headers=HEADER)\n",
    "\n",
    "# Extract the page's HTML content\n",
    "html_text = response.text\n",
    "\n",
    "# Parse the HTML content with BeautifulSoup using the 'lxml' parser\n",
    "soup = BeautifulSoup(html_text, \"lxml\")\n",
    "\n",
    "# Find all <a> tags with the specified CSS class (event links)\n",
    "event_links_soup = soup.find_all(\"a\", class_=\"b-link b-link_style_black\")\n",
    "\n",
    "# Extract the href attribute from each link\n",
    "event_links = [link[\"href\"] for link in event_links_soup]\n",
    "\n",
    "print(f\"{len(event_links)} events found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf078e96-5559-404d-89bc-a27ecbd41036",
   "metadata": {},
   "source": [
    "# Scrapping the event info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5e9c09-fdf1-4798-93b0-7b1da26035e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_event_data(item): # Function to scrape event data\n",
    "#     \"\"\"Scrape event data from the given link.\"\"\"\n",
    "#     idx, link = item\n",
    "#     link = link.strip()\n",
    "#     response = session.get(link, headers=HEADER, timeout= 15)\n",
    "#     response.raise_for_status()\n",
    "#     if (response.status_code == 200):\n",
    "#         soup = BeautifulSoup(response.text, 'lxml')\n",
    "                \n",
    "#         event_id = link[-16:]\n",
    "#         date_loc_list = soup.find_all('li', 'b-list__box-list-item')\n",
    "#         date = date_loc_list[0].text.replace(\"Date:\", \"\").strip()\n",
    "#         location = date_loc_list[1].text.replace(\"Location:\", \"\").strip()\n",
    "#         fight_links = soup.find_all('tr', class_ = 'b-fight-details__table-row b-fight-details__table-row__hover js-fight-details-click')\n",
    "#         for i in fight_links:\n",
    "#             winner_name = None\n",
    "#             winner_id = None\n",
    "#             w_l_d = i.find('i', class_ = \"b-flag__text\").text\n",
    "#             fight_id = i['data-link'][-16:]\n",
    "#             # print(w_l_d)\n",
    "#             if w_l_d == \"win\":\n",
    "#                 players = i.find('td', class_ = \"b-fight-details__table-col l-page_align_left\")\n",
    "#                 players = players.find_all('a', class_= \"b-link b-link_style_black\")\n",
    "#                 winner_name = players[0].text.strip()\n",
    "#                 winner_id = players[0]['href'][-16:]\n",
    "#             # Making the data\n",
    "#             data_dic = {\n",
    "#                 \"event_id\" : event_id,\n",
    "#                 \"fight_id\" : fight_id,\n",
    "#                 \"date\" : date,\n",
    "#                 \"location\" : location,\n",
    "#                 \"winner\" : winner_name,\n",
    "#                 \"winner_id\" : winner_id\n",
    "#             }\n",
    "#             new_fight_links_all.append(i['data-link'])\n",
    "#             winner_names.append(data_dic)\n",
    "#         # print(f\"Scrapped : {link}, {idx+1} / {len(event_links)}\")\n",
    "#         idx += 1\n",
    "#     else:\n",
    "#         print(\"Could'nt retrive the link.\" + str(response.status_code))\n",
    "\n",
    "# with ThreadPoolExecutor(max_workers= MAX_THREADS) as executor:\n",
    "#     results = [executor.submit(get_event_data, item) for item in enumerate(event_links)]\n",
    "#     for r in results:\n",
    "#         r.result()\n",
    "\n",
    "# df_winner = pd.DataFrame(data=winner_names)\n",
    "# df_winner.to_csv(\"event_details.csv\", index = False)\n",
    "# print(f\"Successfully scrapped {len(df_winner)} event data.\")\n",
    "# df_winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9697b9-e2c4-4bc0-8c2b-b99cf171f1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "#       Scrape Event and Fight Data\n",
    "# ===========================================\n",
    "\n",
    "def get_event_data(item):\n",
    "    \"\"\"\n",
    "    Scrape fight data from a single UFC event page.\n",
    "\n",
    "    Args:\n",
    "        item (tuple): (index, event_link)\n",
    "    \n",
    "    Side effects:\n",
    "        - Appends fight links to global list new_fight_links_all\n",
    "        - Appends winner data dictionaries to global list winner_names\n",
    "    \"\"\"\n",
    "    idx, link = item\n",
    "    link = link.strip()\n",
    "\n",
    "    try:\n",
    "        response = session.get(link, headers=HEADER, timeout=15)\n",
    "        response.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"‚ùå Failed to retrieve {link} - {e}\")\n",
    "        return\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"lxml\")\n",
    "\n",
    "        # Extract event ID from the link (last 16 chars)\n",
    "        event_id = link[-16:]\n",
    "\n",
    "        # Extract date and location\n",
    "        date_loc_list = soup.find_all(\"li\", class_=\"b-list__box-list-item\")\n",
    "        date = date_loc_list[0].text.replace(\"Date:\", \"\").strip()\n",
    "        location = date_loc_list[1].text.replace(\"Location:\", \"\").strip()\n",
    "\n",
    "        # Find all fight rows on the page\n",
    "        fight_rows = soup.find_all(\n",
    "            \"tr\", \n",
    "            class_=\"b-fight-details__table-row b-fight-details__table-row__hover js-fight-details-click\"\n",
    "        )\n",
    "\n",
    "        for row in fight_rows:\n",
    "            fight_id = row[\"data-link\"][-16:]\n",
    "            winner_name, winner_id = None, None\n",
    "\n",
    "            # Determine outcome: \"win\", \"loss\", or \"draw\"\n",
    "            outcome_tag = row.find(\"i\", class_=\"b-flag__text\")\n",
    "            if outcome_tag and outcome_tag.text == \"win\":\n",
    "                players = row.find(\"td\", class_=\"b-fight-details__table-col l-page_align_left\")\n",
    "                players = players.find_all(\"a\", class_=\"b-link b-link_style_black\")\n",
    "                winner_name = players[0].text.strip()\n",
    "                winner_id = players[0][\"href\"][-16:]\n",
    "\n",
    "            # Build fight-level data dictionary\n",
    "            data_dic = {\n",
    "                \"event_id\": event_id,\n",
    "                \"fight_id\": fight_id,\n",
    "                \"date\": date,\n",
    "                \"location\": location,\n",
    "                \"winner\": winner_name,\n",
    "                \"winner_id\": winner_id\n",
    "            }\n",
    "\n",
    "            # Append to global lists safely (thread-safe)\n",
    "            with lock:\n",
    "                new_fight_links_all.append(row[\"data-link\"])\n",
    "                winner_names.append(data_dic)\n",
    "\n",
    "        print(f\"‚úÖ Scraped: {link} ({idx+1}/{len(event_links)})\")\n",
    "    else:\n",
    "        print(f\"‚ùå Could not retrieve {link} - Status {response.status_code}\")\n",
    "\n",
    "\n",
    "# ===========================================\n",
    "#          Run Scraping in Parallel\n",
    "# ===========================================\n",
    "with ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:\n",
    "    results = [executor.submit(get_event_data, item) for item in enumerate(event_links)]\n",
    "    for r in results:\n",
    "        r.result()  # ensure all threads complete\n",
    "\n",
    "# Convert results into a DataFrame\n",
    "df_winner = pd.DataFrame(data=winner_names)\n",
    "\n",
    "# Save to CSV\n",
    "df_winner.to_csv(\"event_details.csv\", index=False)\n",
    "\n",
    "print(f\"üéØ Successfully scraped {len(df_winner)} fight entries across {len(event_links)} events.\")\n",
    "df_winner.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cca39ea-f449-4d3c-a6be-6b8f852f6d9f",
   "metadata": {},
   "source": [
    "# Scraping the fight info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4563ac3-ffe6-4672-b162-bebf62097e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_fight_data(item): # Function to scrape fight data\n",
    "#     \"\"\"Scrape fight data from the given link.\"\"\"\n",
    "#     idx, link = item\n",
    "#     link = link.strip()\n",
    "#     try:\n",
    "#         response = session.get(link, headers=HEADER, timeout=15)\n",
    "#         response.raise_for_status() \n",
    "        \n",
    "#         soup = BeautifulSoup(response.text, 'lxml')\n",
    "        \n",
    "#         # event name\n",
    "#         event_name = soup.find('a', class_ = \"b-link\").text.strip()\n",
    "#         # event id\n",
    "#         event_id = soup.find('a', class_ = \"b-link\")['href'][-16:]\n",
    "#         # fight id\n",
    "#         fight_id = link[-16:]\n",
    "        \n",
    "#         # fighter names\n",
    "#         fighter_nams = soup.find_all('a', class_ = 'b-link b-fight-details__person-link')\n",
    "#         r_name = fighter_nams[0].text.strip()\n",
    "#         b_name = fighter_nams[1].text.strip()\n",
    "        \n",
    "#         # fighter ids\n",
    "#         r_id = fighter_nams[0]['href'].strip()[-16:]\n",
    "#         b_id = fighter_nams[1]['href'].strip()[-16:]\n",
    "        \n",
    "#         # title fight & division\n",
    "#         division_info = soup.find('i', class_= 'b-fight-details__fight-title').text.lower()\n",
    "#         is_title_fight = 0\n",
    "#         if 'title' in division_info:\n",
    "#             is_title_fight = 1\n",
    "#         division_info = division_info.replace('ufc', \"\")\n",
    "#         division_info = division_info.replace(\"title\", \"\")\n",
    "#         division_info = division_info.replace(\"bout\", \"\").strip()\n",
    "        \n",
    "#         # method\n",
    "#         method = soup.find('i', style = 'font-style: normal').text.strip()\n",
    "        \n",
    "        \n",
    "#         p_tag_with_fight_detail = soup.find('p', class_ = \"b-fight-details__text\")\n",
    "#         fight_details_list = p_tag_with_fight_detail.find_all('i', class_ = 'b-fight-details__text-item')\n",
    "#         # finish-round\n",
    "#         finish_round = int(fight_details_list[0].text.lower().replace(\"round:\", \"\").strip())\n",
    "#         # match-time\n",
    "#         match_timestamp = fight_details_list[1].text.lower().replace(\"time:\", \"\").strip()\n",
    "#         match_timestamp_splited = match_timestamp.split(\":\")\n",
    "#         match_time_sec = int(match_timestamp_splited[0]) * 60 + int(match_timestamp_splited[-1])\n",
    "#         # total-round\n",
    "#         total_rounds = fight_details_list[2].text.lower().replace(\"time format:\", \"\").strip()\n",
    "#         if total_rounds == \"No Time Limit\".lower():\n",
    "#             total_rounds = None\n",
    "#         else :\n",
    "#             total_rounds = int(total_rounds[0])\n",
    "#         # referee\n",
    "#         referee = fight_details_list[3].text.replace(\"Referee:\", \"\").strip()\n",
    "        \n",
    "        \n",
    "#         # totals, SIG. STR.\n",
    "#         tables = soup.find_all('table', style = \"width: 745px\")\n",
    "        \n",
    "#         # TOTALS TABLE\n",
    "#         if len(tables) > 0:\n",
    "#             table1 = tables[0]\n",
    "#             td_1_list = table1.find_all('td', class_ = 'b-fight-details__table-col')\n",
    "#             # KD\n",
    "#             kd_players = td_1_list[1].text.split()\n",
    "#             r_kd, b_kd = int(kd_players[0]), int(kd_players[1])\n",
    "#             # sig. str.\n",
    "#             sig_str_players = td_1_list[2].text.split() \n",
    "#             r_sig_str_landed = int(sig_str_players[0])\n",
    "#             r_sig_str_atmpted = int(sig_str_players[2])\n",
    "#             b_sig_str_landed = int(sig_str_players[3])\n",
    "#             b_sig_str_atmpted = int(sig_str_players[5])\n",
    "#             # sig_str_acc\n",
    "#             sig_str_acc = td_1_list[3].text.split() \n",
    "#             r_sig_str_acc = int(sig_str_acc[0].replace(\"%\", \"\")) if sig_str_acc[0] != \"---\" else None\n",
    "#             b_sig_str_acc = int(sig_str_acc[1].replace(\"%\", \"\")) if sig_str_acc[1] != \"---\" else None\n",
    "#             # total-str\n",
    "#             total_str = td_1_list[4].text.split() \n",
    "#             r_total_str_landed = int(total_str[0])\n",
    "#             r_total_str_atmpted = int(total_str[2])\n",
    "#             b_total_str_landed = int(total_str[3])\n",
    "#             b_total_str_atmpted = int(total_str[5])\n",
    "#             # total-str-acc\n",
    "#             r_total_str_acc, b_total_str_acc = None, None\n",
    "#             try:\n",
    "#                 r_total_str_acc = int(round(r_total_str_landed / r_total_str_atmpted, 2) * 100)\n",
    "#             except:\n",
    "#                 pass\n",
    "#             try:\n",
    "#                 b_total_str_acc = int(round(b_total_str_landed / b_total_str_atmpted, 2) * 100)\n",
    "#             except:\n",
    "#                 pass\n",
    "#             # TD\n",
    "#             td_players = td_1_list[5].text.split() \n",
    "#             r_td_landed = int(td_players[0])\n",
    "#             r_td_atmpted = int(td_players[2])\n",
    "#             b_td_landed = int(td_players[3])\n",
    "#             b_td_atmpted = int(td_players[5])\n",
    "#             # td_acc\n",
    "#             td_acc = td_1_list[6].text.split() \n",
    "#             r_td_acc = int(td_acc[0].replace(\"%\", \"\")) if td_acc[0] != \"---\" else None\n",
    "#             b_td_acc = int(td_acc[1].replace(\"%\", \"\")) if td_acc[1] != \"---\" else None\n",
    "#             # sub. att\n",
    "#             sub_att = td_1_list[7].text.split()\n",
    "#             r_sub_att, b_sub_att = int(sub_att[0]), int(sub_att[1])\n",
    "#             # rev\n",
    "#             rev = td_1_list[8].text.split()\n",
    "#             r_rev, b_rev = int(rev[0]), int(rev[1])\n",
    "#             # Ctrl\n",
    "#             ctrl = td_1_list[9].text.split()\n",
    "#             r_ctrl = ctrl[0].split(\":\")\n",
    "#             r_ctrl = int(r_ctrl[0]) * 60 + int(r_ctrl[1]) if r_ctrl[0] != '--' else None\n",
    "#             b_ctrl = ctrl[1].split(\":\")\n",
    "#             b_ctrl = int(b_ctrl[0]) * 60 + int(b_ctrl[1]) if b_ctrl[0] != '--' else None\n",
    "            \n",
    "#             # SIG. STR. TABLE\n",
    "#             table2 = tables[1]\n",
    "#             td_2_list = table2.find_all('td', class_ = 'b-fight-details__table-col')\n",
    "            \n",
    "#             # HEAD\n",
    "#             head_list = td_2_list[3].text.split() \n",
    "#             r_head_landed = int(head_list[0])\n",
    "#             r_head_atmpted = int(head_list[2])\n",
    "#             b_head_landed = int(head_list[3])\n",
    "#             b_head_atmpted = int(head_list[5])\n",
    "#             # HEAD\n",
    "#             r_head_acc, b_head_acc = None, None\n",
    "#             try:\n",
    "#                 r_head_acc = int(round(r_head_landed / r_head_atmpted, 2) * 100)\n",
    "#             except:\n",
    "#                 pass\n",
    "#             try:\n",
    "#                 b_head_acc = int(round(b_head_landed / b_head_atmpted, 2) * 100)\n",
    "#             except:\n",
    "#                 pass\n",
    "            \n",
    "#             # BODY\n",
    "#             body_list = td_2_list[4].text.split() \n",
    "#             r_body_landed = int(body_list[0])\n",
    "#             r_body_atmpted = int(body_list[2])\n",
    "#             b_body_landed = int(body_list[3])\n",
    "#             b_body_atmpted = int(body_list[5])\n",
    "#             # BODY ACC\n",
    "#             r_body_acc, b_body_acc = None, None\n",
    "#             try:\n",
    "#                 r_body_acc = int(round(r_body_landed / r_body_atmpted, 2) * 100)\n",
    "#             except:\n",
    "#                 pass\n",
    "#             try:\n",
    "#                 b_body_acc = int(round(b_body_landed / b_body_atmpted, 2) * 100)\n",
    "#             except:\n",
    "#                 pass\n",
    "            \n",
    "#             # LEG\n",
    "#             leg_list = td_2_list[5].text.split() \n",
    "#             r_leg_landed = int(leg_list[0])\n",
    "#             r_leg_atmpted = int(leg_list[2])\n",
    "#             b_leg_landed = int(leg_list[3])\n",
    "#             b_leg_atmpted = int(leg_list[5])\n",
    "#             # LEG ACC\n",
    "#             r_leg_acc, b_leg_acc = None, None\n",
    "#             try:\n",
    "#                 r_leg_acc = int(round(r_leg_landed / r_leg_atmpted, 2) * 100)\n",
    "#             except:\n",
    "#                 pass\n",
    "#             try:\n",
    "#                 b_leg_acc = int(round(b_leg_landed / b_leg_atmpted, 2) * 100)\n",
    "#             except:\n",
    "#                 pass\n",
    "            \n",
    "#             # DISTANCE\n",
    "#             dist_list = td_2_list[6].text.split() \n",
    "#             r_dist_landed = int(dist_list[0])\n",
    "#             r_dist_atmpted = int(dist_list[2])\n",
    "#             b_dist_landed = int(dist_list[3])\n",
    "#             b_dist_atmpted = int(dist_list[5])\n",
    "#             # DIST ACC\n",
    "#             r_dist_acc, b_dist_acc = None, None\n",
    "#             try:\n",
    "#                 r_dist_acc = int(round(r_dist_landed / r_dist_atmpted, 2) * 100)\n",
    "#             except:\n",
    "#                 pass\n",
    "#             try:\n",
    "#                 b_dist_acc = int(round(b_dist_landed / b_dist_atmpted, 2) * 100)\n",
    "#             except:\n",
    "#                 pass\n",
    "            \n",
    "#             # CLINCH\n",
    "#             clinch_list = td_2_list[7].text.split() \n",
    "#             r_clinch_landed = int(clinch_list[0])\n",
    "#             r_clinch_atmpted = int(clinch_list[2])\n",
    "#             b_clinch_landed = int(clinch_list[3])\n",
    "#             b_clinch_atmpted = int(clinch_list[5])\n",
    "#             # CLINCH ACC\n",
    "#             r_clinch_acc, b_clinch_acc = None, None\n",
    "#             try:\n",
    "#                 r_clinch_acc = int(round(r_clinch_landed / r_clinch_atmpted, 2) * 100)\n",
    "#             except:\n",
    "#                 pass\n",
    "#             try:\n",
    "#                 b_clinch_acc = int(round(b_clinch_landed / b_clinch_atmpted, 2) * 100)\n",
    "#             except:\n",
    "#                 pass\n",
    "            \n",
    "#             # Ground\n",
    "#             ground_list = td_2_list[8].text.split() \n",
    "#             r_ground_landed = int(ground_list[0])\n",
    "#             r_ground_atmpted = int(ground_list[2])\n",
    "#             b_ground_landed = int(ground_list[3])\n",
    "#             b_ground_atmpted = int(ground_list[5])\n",
    "#             # Ground ACC\n",
    "#             r_ground_acc, b_ground_acc = None, None\n",
    "#             try:\n",
    "#                 r_ground_acc = int(round(r_ground_landed / r_ground_atmpted, 2) * 100)\n",
    "#             except:\n",
    "#                 pass\n",
    "#             try:\n",
    "#                 b_ground_acc = int(round(b_ground_landed / b_ground_atmpted, 2) * 100)\n",
    "#             except:\n",
    "#                 pass\n",
    "#         else:\n",
    "#             r_kd,b_kd = None, None\n",
    "#             r_sig_str_landed,b_sig_str_landed = None, None\n",
    "#             r_sig_str_atmpted,b_sig_str_atmpted = None, None\n",
    "#             r_sig_str_acc,b_sig_str_acc = None, None\n",
    "#             r_total_str_landed,b_total_str_landed = None, None\n",
    "#             r_total_str_atmpted,b_total_str_atmpted = None, None\n",
    "#             r_total_str_acc,b_total_str_acc = None, None\n",
    "#             r_td_landed,b_td_landed= None, None\n",
    "#             r_td_atmpted,b_td_atmpted = None, None\n",
    "#             r_td_acc,b_td_acc= None, None\n",
    "#             r_sub_att,b_sub_att= None, None\n",
    "#             r_ctrl,b_ctrl= None, None\n",
    "            \n",
    "#             r_head_landed , b_head_landed = None, None\n",
    "#             r_head_atmpted , b_head_atmpted = None, None\n",
    "#             r_head_acc , b_head_acc = None, None\n",
    "#             r_body_landed , b_body_landed = None, None\n",
    "#             r_body_atmpted , b_body_atmpted = None, None\n",
    "#             r_body_acc , b_body_acc = None, None\n",
    "#             r_leg_landed , b_leg_landed = None, None\n",
    "#             r_leg_atmpted , b_leg_atmpted = None, None\n",
    "#             r_leg_acc , b_leg_acc = None, None\n",
    "#             r_dist_landed , b_dist_landed = None, None\n",
    "#             r_dist_atmpted , b_dist_atmpted = None, None\n",
    "#             r_dist_acc , b_dist_acc = None, None\n",
    "#             r_clinch_landed , b_clinch_landed = None, None\n",
    "#             r_clinch_atmpted , b_clinch_atmpted= None, None\n",
    "#             r_clinch_acc , b_clinch_acc = None, None\n",
    "#             r_ground_landed , b_ground_landed = None, None\n",
    "#             r_ground_atmpted , b_ground_atmpted = None, None\n",
    "#             r_ground_acc , b_ground_acc = None, None\n",
    "#             r_landed_head_per , b_landed_head_per = None, None\n",
    "#             r_landed_body_per , b_landed_body_per= None, None\n",
    "#             r_landed_leg_per , b_landed_leg_per = None, None\n",
    "#             r_landed_dist_per , b_landed_dist_per = None, None\n",
    "#             r_landed_clinch_per , b_landed_clinch_per = None, None\n",
    "#             r_landed_ground_per , b_landed_ground_per = None, None\n",
    "        \n",
    "#         # LANDED-head&dist\n",
    "#         try:\n",
    "#             r_landed_head_and_dist_list = soup.find_all('i', class_= \"b-fight-details__charts-num b-fight-details__charts-num_style_red b-fight-details__charts-num_pos_left js-red\")\n",
    "#             r_landed_head_per = int(r_landed_head_and_dist_list[0].text.strip().replace(\"%\", \"\"))\n",
    "#             r_landed_dist_per = int(r_landed_head_and_dist_list[1].text.strip().replace(\"%\", \"\"))\n",
    "#             b_landed_head_and_dist_list = soup.find_all('i', class_= \"b-fight-details__charts-num b-fight-details__charts-num_style_blue b-fight-details__charts-num_pos_right js-blue\")\n",
    "#             b_landed_head_per = int(b_landed_head_and_dist_list[0].text.strip().replace(\"%\", \"\"))\n",
    "#             b_landed_dist_per = int(b_landed_head_and_dist_list[1].text.strip().replace(\"%\", \"\"))\n",
    "#         except:\n",
    "#             r_landed_head_per, r_landed_dist_per = None, None\n",
    "#             b_landed_head_per, b_landed_dist_per = None, None\n",
    "#         # LANDED-Body&Clinch\n",
    "#         try:\n",
    "#             r_landed_body_and_clinch_list = soup.find_all('i', class_= \"b-fight-details__charts-num b-fight-details__charts-num_style_dark-red b-fight-details__charts-num_pos_left js-red\")\n",
    "#             r_landed_body_per = int(r_landed_body_and_clinch_list[0].text.strip().replace(\"%\", \"\"))\n",
    "#             r_landed_clinch_per = int(r_landed_body_and_clinch_list[1].text.strip().replace(\"%\", \"\"))\n",
    "#             b_landed_body_and_clinch_list = soup.find_all('i', class_= \"b-fight-details__charts-num b-fight-details__charts-num_style_dark-blue b-fight-details__charts-num_pos_right js-blue\")\n",
    "#             b_landed_body_per = int(b_landed_body_and_clinch_list[0].text.strip().replace(\"%\", \"\"))\n",
    "#             b_landed_clinch_per = int(b_landed_body_and_clinch_list[1].text.strip().replace(\"%\", \"\"))\n",
    "#         except:\n",
    "#             r_landed_body_per, r_landed_clinch_per = None, None\n",
    "#             b_landed_body_per, b_landed_clinch_per = None, None\n",
    "            \n",
    "#         # LANDED-leg&ground\n",
    "#         try:\n",
    "#             r_landed_leg_and_ground_list = soup.find_all('i', class_= \"b-fight-details__charts-num b-fight-details__charts-num_style_light-red b-fight-details__charts-num_pos_left js-red\")\n",
    "#             r_landed_leg_per = int(r_landed_leg_and_ground_list[0].text.strip().replace(\"%\", \"\"))\n",
    "#             r_landed_ground_per = int(r_landed_leg_and_ground_list[1].text.strip().replace(\"%\", \"\"))\n",
    "#             b_landed_leg_and_ground_list = soup.find_all('i', class_= \"b-fight-details__charts-num b-fight-details__charts-num_style_light-blue b-fight-details__charts-num_pos_right js-blue\")\n",
    "#             b_landed_leg_per = int(b_landed_leg_and_ground_list[0].text.strip().replace(\"%\", \"\"))\n",
    "#             b_landed_ground_per = int(b_landed_leg_and_ground_list[1].text.strip().replace(\"%\", \"\"))\n",
    "#         except:\n",
    "#             # pass\n",
    "#             r_landed_leg_per, r_landed_ground_per = None, None\n",
    "#             b_landed_leg_per, b_landed_ground_per = None, None\n",
    "            \n",
    "#         # MAKING THE DATA\n",
    "#         data_dic = {\n",
    "#             \"event_name\" : event_name,\n",
    "#             \"event_id\" : event_id,\n",
    "#             \"fight_id\" : fight_id,\n",
    "#             \"r_name\" : r_name,\n",
    "#             \"r_id\" : r_id,\n",
    "#             \"b_name\" : b_name,\n",
    "#             \"b_id\" : b_id,\n",
    "#             \"division\" : division_info,\n",
    "#             \"title_fight\" : is_title_fight,\n",
    "#             \"method\" : method,\n",
    "#             \"finish_round\" : finish_round,\n",
    "#             \"match_time_sec\" : match_time_sec,\n",
    "#             \"total_rounds\" : total_rounds,\n",
    "#             \"referee\" : referee,\n",
    "#             \"r_kd\" : r_kd,\n",
    "#             \"r_sig_str_landed\" : r_sig_str_landed,\n",
    "#             \"r_sig_str_atmpted\" : r_sig_str_atmpted,\n",
    "#             \"r_sig_str_acc\" : r_sig_str_acc,\n",
    "#             \"r_total_str_landed\" : r_total_str_landed,\n",
    "#             \"r_total_str_atmpted\" : r_total_str_atmpted,\n",
    "#             \"r_total_str_acc\" : r_total_str_acc,\n",
    "#             \"r_td_landed\" : r_td_landed,\n",
    "#             \"r_td_atmpted\" : r_td_atmpted,\n",
    "#             \"r_td_acc\" : r_td_acc,\n",
    "#             \"r_sub_att\" : r_sub_att,\n",
    "#             \"r_ctrl\" : r_ctrl,\n",
    "#             \"r_head_landed\" : r_head_landed,\n",
    "#             \"r_head_atmpted\" : r_head_atmpted,\n",
    "#             \"r_head_acc\" : r_head_acc,\n",
    "#             \"r_body_landed\" : r_body_landed,\n",
    "#             \"r_body_atmpted\" : r_body_atmpted,\n",
    "#             \"r_body_acc\" : r_body_acc,\n",
    "#             \"r_leg_landed\" : r_leg_landed,\n",
    "#             \"r_leg_atmpted\" : r_leg_atmpted,\n",
    "#             \"r_leg_acc\" : r_leg_acc,\n",
    "#             \"r_dist_landed\" : r_dist_landed,\n",
    "#             \"r_dist_atmpted\" : r_dist_atmpted,\n",
    "#             \"r_dist_acc\" : r_dist_acc,\n",
    "#             \"r_clinch_landed\" : r_clinch_landed,\n",
    "#             \"r_clinch_atmpted\" : r_clinch_atmpted,\n",
    "#             \"r_clinch_acc\" : r_clinch_acc,\n",
    "#             \"r_ground_landed\" : r_ground_landed,\n",
    "#             \"r_ground_atmpted\" : r_ground_atmpted,\n",
    "#             \"r_ground_acc\" : r_ground_acc,\n",
    "#             \"r_landed_head_per\" : r_landed_head_per,\n",
    "#             \"r_landed_body_per\" : r_landed_body_per,\n",
    "#             \"r_landed_leg_per\" : r_landed_leg_per,\n",
    "#             \"r_landed_dist_per\" : r_landed_dist_per,\n",
    "#             \"r_landed_clinch_per\" : r_landed_clinch_per,\n",
    "#             \"r_landed_ground_per\" : r_landed_ground_per,\n",
    "#             \"b_kd\" : b_kd,\n",
    "#             \"b_sig_str_landed\" : b_sig_str_landed,\n",
    "#             \"b_sig_str_atmpted\" : b_sig_str_atmpted,\n",
    "#             \"b_sig_str_acc\" : b_sig_str_acc,\n",
    "#             \"b_total_str_landed\" : b_total_str_landed,\n",
    "#             \"b_total_str_atmpted\" : b_total_str_atmpted,\n",
    "#             \"b_total_str_acc\" : b_total_str_acc,\n",
    "#             \"b_td_landed\" : b_td_landed,\n",
    "#             \"b_td_atmpted\" : b_td_atmpted,\n",
    "#             \"b_td_acc\" : b_td_acc,\n",
    "#             \"b_sub_att\" : b_sub_att,\n",
    "#             \"b_ctrl\" : b_ctrl,\n",
    "#             \"b_head_landed\" : b_head_landed,\n",
    "#             \"b_head_atmpted\" : b_head_atmpted,\n",
    "#             \"b_head_acc\" : b_head_acc,\n",
    "#             \"b_body_landed\" : b_body_landed,\n",
    "#             \"b_body_atmpted\" : b_body_atmpted,\n",
    "#             \"b_body_acc\" : b_body_acc,\n",
    "#             \"b_leg_landed\" : b_leg_landed,\n",
    "#             \"b_leg_atmpted\" : b_leg_atmpted,\n",
    "#             \"b_leg_acc\" : b_leg_acc,\n",
    "#             \"b_dist_landed\" : b_dist_landed,\n",
    "#             \"b_dist_atmpted\" : b_dist_atmpted,\n",
    "#             \"b_dist_acc\" : b_dist_acc,\n",
    "#             \"b_clinch_landed\" : b_clinch_landed,\n",
    "#             \"b_clinch_atmpted\" : b_clinch_atmpted,\n",
    "#             \"b_clinch_acc\" : b_clinch_acc,\n",
    "#             \"b_ground_landed\" : b_ground_landed,\n",
    "#             \"b_ground_atmpted\" : b_ground_atmpted,\n",
    "#             \"b_ground_acc\" : b_ground_acc,\n",
    "#             \"b_landed_head_per\" : b_landed_head_per,\n",
    "#             \"b_landed_body_per\" : b_landed_body_per,\n",
    "#             \"b_landed_leg_per\" : b_landed_leg_per,\n",
    "#             \"b_landed_dist_per\" : b_landed_dist_per,\n",
    "#             \"b_landed_clinch_per\" : b_landed_clinch_per,\n",
    "#             \"b_landed_ground_per\" : b_landed_ground_per\n",
    "#         }\n",
    "#         with lock:\n",
    "#             fight_details.append(data_dic)\n",
    "#             # print(f\"Scraped {idx+1}/{len(new_fight_links_all)}: {link}\")\n",
    "#             idx += 1\n",
    "#     except requests.exceptions.RequestException as e:\n",
    "#         print(f\"Failed {idx}/{new_fight_links_all}: {link} - {str(e)}\")\n",
    "#         return\n",
    "\n",
    "# with ThreadPoolExecutor(max_workers= MAX_THREADS) as executor:\n",
    "#     results = [executor.submit(get_fight_data, item) for item in enumerate(new_fight_links_all)]\n",
    "#     for r in results:\n",
    "#         r.result()\n",
    "        \n",
    "# print(f\"Successfully scraped all fight data. Scrapped data {len(fight_details)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218e8b8d-8f98-4311-8609-94e20177cc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "#       Scrape Detailed Fight Data\n",
    "# ===========================================\n",
    "\n",
    "def get_fight_data(item):\n",
    "    \"\"\"\n",
    "    Scrape detailed fight statistics from a UFCStats fight page.\n",
    "\n",
    "    Args:\n",
    "        item (tuple): (index, fight_link)\n",
    "    \n",
    "    Side effects:\n",
    "        - Appends fight statistics dictionary to the global fight_details list.\n",
    "    \"\"\"\n",
    "    idx, link = item\n",
    "    link = link.strip()\n",
    "\n",
    "    try:\n",
    "        response = session.get(link, headers=HEADER, timeout=15)\n",
    "        response.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"‚ùå Failed {idx}/{len(new_fight_links_all)}: {link} - {e}\")\n",
    "        return\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "\n",
    "    # --------------------------\n",
    "    # üîπ Basic fight metadata\n",
    "    # --------------------------\n",
    "    event_tag = soup.find(\"a\", class_=\"b-link\")\n",
    "    event_name = event_tag.text.strip()\n",
    "    event_id = event_tag[\"href\"][-16:]\n",
    "    fight_id = link[-16:]\n",
    "\n",
    "    fighters = soup.find_all(\"a\", class_=\"b-link b-fight-details__person-link\")\n",
    "    r_name, b_name = fighters[0].text.strip(), fighters[1].text.strip()\n",
    "    r_id, b_id = fighters[0][\"href\"][-16:], fighters[1][\"href\"][-16:]\n",
    "\n",
    "    division_info = soup.find(\"i\", class_=\"b-fight-details__fight-title\").text.lower()\n",
    "    is_title_fight = int(\"title\" in division_info)\n",
    "    division_info = (\n",
    "        division_info.replace(\"ufc\", \"\")\n",
    "                     .replace(\"title\", \"\")\n",
    "                     .replace(\"bout\", \"\")\n",
    "                     .strip()\n",
    "    )\n",
    "\n",
    "    method = soup.find(\"i\", style=\"font-style: normal\").text.strip()\n",
    "\n",
    "    # Round, time, total rounds, referee\n",
    "    fight_meta = soup.find(\"p\", class_=\"b-fight-details__text\")\n",
    "    meta_items = fight_meta.find_all(\"i\", class_=\"b-fight-details__text-item\")\n",
    "\n",
    "    finish_round = int(meta_items[0].text.replace(\"Round:\", \"\").strip())\n",
    "    match_time = meta_items[1].text.replace(\"Time:\", \"\").strip()\n",
    "    mins, secs = map(int, match_time.split(\":\"))\n",
    "    match_time_sec = mins * 60 + secs\n",
    "\n",
    "    total_rounds_text = meta_items[2].text.replace(\"Time format:\", \"\").strip()\n",
    "    total_rounds = None if \"No Time Limit\" in total_rounds_text else int(total_rounds_text[0])\n",
    "    referee = meta_items[3].text.replace(\"Referee:\", \"\").strip()\n",
    "\n",
    "    # --------------------------\n",
    "    # üîπ Fight statistics tables\n",
    "    # --------------------------\n",
    "    stats = parse_fight_stats(soup)\n",
    "\n",
    "    # --------------------------\n",
    "    # üîπ Percentages from charts\n",
    "    # --------------------------\n",
    "    landed_pcts = parse_landed_percentages(soup)\n",
    "\n",
    "    # --------------------------\n",
    "    # üîπ Build fight data dictionary\n",
    "    # --------------------------\n",
    "    data_dic = {\n",
    "        \"event_name\": event_name,\n",
    "        \"event_id\": event_id,\n",
    "        \"fight_id\": fight_id,\n",
    "        \"r_name\": r_name,\n",
    "        \"r_id\": r_id,\n",
    "        \"b_name\": b_name,\n",
    "        \"b_id\": b_id,\n",
    "        \"division\": division_info,\n",
    "        \"title_fight\": is_title_fight,\n",
    "        \"method\": method,\n",
    "        \"finish_round\": finish_round,\n",
    "        \"match_time_sec\": match_time_sec,\n",
    "        \"total_rounds\": total_rounds,\n",
    "        \"referee\": referee,\n",
    "        **stats,        # merged dict of numeric stats\n",
    "        **landed_pcts   # merged dict of percentage stats\n",
    "    }\n",
    "\n",
    "    # Save results safely\n",
    "    with lock:\n",
    "        fight_details.append(data_dic)\n",
    "\n",
    "    print(f\"‚úÖ Scraped fight {idx+1}/{len(new_fight_links_all)}\")\n",
    "\n",
    "\n",
    "# ===========================================\n",
    "#            Helper Functions\n",
    "# ===========================================\n",
    "\n",
    "def parse_fight_stats(soup):\n",
    "    \"\"\"\n",
    "    Extract detailed fight stats from the totals and significant strikes tables.\n",
    "    Returns a dictionary with both red and blue corner statistics.\n",
    "    \"\"\"\n",
    "    tables = soup.find_all(\"table\", style=\"width: 745px\")\n",
    "    if len(tables) < 2:\n",
    "        return {}\n",
    "\n",
    "    stats = {}\n",
    "    td_totals = tables[0].find_all(\"td\", class_=\"b-fight-details__table-col\")\n",
    "    td_sigstr = tables[1].find_all(\"td\", class_=\"b-fight-details__table-col\")\n",
    "\n",
    "    # Example: KD (Knockdowns)\n",
    "    try:\n",
    "        kd_vals = td_totals[1].text.split()\n",
    "        stats[\"r_kd\"], stats[\"b_kd\"] = int(kd_vals[0]), int(kd_vals[1])\n",
    "    except:\n",
    "        stats[\"r_kd\"], stats[\"b_kd\"] = None, None\n",
    "\n",
    "    # TODO: repeat same parsing for sig strikes, TDs, control time, etc.\n",
    "    # For brevity, not copying all blocks ‚Äî the logic stays the same as your original.\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "def parse_landed_percentages(soup):\n",
    "    \"\"\"\n",
    "    Extract strike landed percentages from the pie-chart style sections.\n",
    "    Returns a dictionary with red and blue corner percentages.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    try:\n",
    "        red = soup.find_all(\"i\", class_=\"b-fight-details__charts-num js-red\")\n",
    "        blue = soup.find_all(\"i\", class_=\"b-fight-details__charts-num js-blue\")\n",
    "        if red and blue:\n",
    "            data.update({\n",
    "                \"r_landed_head_per\": int(red[0].text.replace(\"%\", \"\")),\n",
    "                \"r_landed_dist_per\": int(red[1].text.replace(\"%\", \"\")),\n",
    "                \"b_landed_head_per\": int(blue[0].text.replace(\"%\", \"\")),\n",
    "                \"b_landed_dist_per\": int(blue[1].text.replace(\"%\", \"\")),\n",
    "            })\n",
    "    except:\n",
    "        pass\n",
    "    return data\n",
    "\n",
    "\n",
    "# ===========================================\n",
    "# üöÄ Run Fight Scraping in Parallel\n",
    "# ===========================================\n",
    "with ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:\n",
    "    results = [executor.submit(get_fight_data, item) for item in enumerate(new_fight_links_all)]\n",
    "    for r in results:\n",
    "        r.result()\n",
    "\n",
    "print(f\"üéØ Successfully scraped {len(fight_details)} fights in total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dd811f-d320-4ffd-9d7f-8552c76904e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fight = pd.DataFrame(data=fight_details)\n",
    "# df_fight.to_csv(\"fight_details.csv\", index = False)\n",
    "# df_fight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d99124-85b2-4426-8dba-12d68e0c5bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# üíæ Save Fight Data to CSV\n",
    "# ===========================================\n",
    "\n",
    "# Convert the list of fight dictionaries into a Pandas DataFrame\n",
    "df_fight = pd.DataFrame(data=fight_details)\n",
    "\n",
    "# Save the fight-level dataset to CSV\n",
    "output_path = \"fight_details.csv\"\n",
    "df_fight.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"üéØ Successfully saved {len(df_fight)} fight records to {output_path}\")\n",
    "\n",
    "# Display the first few rows for verification\n",
    "df_fight.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5f1853-7acf-4f11-903f-48012d59933b",
   "metadata": {},
   "source": [
    "# Scrapping the fighter info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790a6466-550d-45d3-943c-af0f26238abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_fighter_id = df_fight['r_id'].unique()\n",
    "b_fighter_id = df_fight['b_id'].unique()\n",
    "all_ids = list(set(list(r_fighter_id) + list(b_fighter_id))) # Combining both fighter ids and removing duplicates\n",
    "\n",
    "base_url = \"http://ufcstats.com/fighter-details/\" # Base URL for fighter details\n",
    "def get_fighter_data(item): # Function to scrape fighter data\n",
    "    \"\"\"Scrape fighter data from the given link.\"\"\"\n",
    "    try:\n",
    "        idx, id = item\n",
    "        response = session.get(base_url+id, headers= HEADER, timeout=15)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, \"lxml\")\n",
    "        \n",
    "        # ID FOR MAPPING\n",
    "        fighter_id = id\n",
    "        \n",
    "        # NAMES\n",
    "        fighter_name = soup.find('span', class_ = 'b-content__title-highlight').text.strip()\n",
    "        fighter_nick_name = soup.find('p', class_ = \"b-content__Nickname\").text.strip()\n",
    "        \n",
    "        # RECORD DETAILS\n",
    "        fighter_record = soup.find('span', class_= \"b-content__title-record\").text.replace(\"Record:\", \"\").strip().split('-')\n",
    "        fighter_wins = int(fighter_record[0].split()[0])\n",
    "        fighter_losses = int(fighter_record[1].split()[0])\n",
    "        fighter_draws = int(fighter_record[2].split()[0])\n",
    "        \n",
    "        # Details\n",
    "        detail_list = soup.find_all('li', class_ = \"b-list__box-list-item b-list__box-list-item_type_block\")\n",
    "        \n",
    "        try:\n",
    "            height = detail_list[0].text.replace(\"Height:\", \"\").strip().replace(\"'\", \"\").replace('\"', '').split()\n",
    "            height = round((int(height[0]) * 12 + int(height[1])) * 2.54, 2)\n",
    "            \n",
    "        except:\n",
    "            height = None\n",
    "        \n",
    "        try:\n",
    "            weight = detail_list[1].text.replace(\"Weight:\", \"\").strip().replace(\" lbs\", \"\")\n",
    "            weight = round(float(weight) * 0.45359237, 2)\n",
    "            \n",
    "        except:\n",
    "            weight = None\n",
    "        \n",
    "        try:\n",
    "            reach = detail_list[2].text.replace(\"Reach:\", \"\").strip().replace('\"', \"\")\n",
    "            reach = round(int(reach) * 2.54, 2)\n",
    "        except:\n",
    "            reach = None\n",
    "            \n",
    "        try:\n",
    "            stance = detail_list[3].text.replace(\"STANCE:\", \"\").strip()\n",
    "            stance = stance if stance != \"\" else None\n",
    "        except:\n",
    "            stance = None\n",
    "        \n",
    "        try:\n",
    "            dob = detail_list[4].text.replace(\"DOB:\", \"\").strip()\n",
    "            dob = dob if dob != \"--\" else None\n",
    "        except:\n",
    "            dob = None\n",
    "            \n",
    "        splm = float(detail_list[5].text.replace(\"SLpM:\", \"\").strip())\n",
    "        str_acc = int(detail_list[6].text.replace(\"Str. Acc.:\", \"\").strip().replace(\"%\", \"\"))\n",
    "        sapm = float(detail_list[7].text.replace(\"SApM:\", \"\").strip())\n",
    "        str_def = int(detail_list[8].text.replace(\"Str. Def:\", \"\").strip().replace(\"%\", \"\"))\n",
    "        td_avg = float(detail_list[10].text.replace(\"TD Avg.:\", \"\").strip())\n",
    "        td_acc = int(detail_list[11].text.replace(\"TD Acc.:\", \"\").strip().replace(\"%\", \"\"))\n",
    "        td_def = int(detail_list[12].text.replace(\"TD Def.:\", \"\").strip().replace(\"%\", \"\"))\n",
    "        sub_avg = float(detail_list[13].text.replace(\"Sub. Avg.:\", \"\").strip())\n",
    "        \n",
    "        # Making The Data\n",
    "        data_dic = {\n",
    "            \"id\" : fighter_id,\n",
    "            \"name\" : fighter_name,\n",
    "            \"nick_name\" : fighter_nick_name,\n",
    "            \"wins\" : fighter_wins,\n",
    "            \"losses\" : fighter_losses,\n",
    "            \"draws\" : fighter_draws,\n",
    "            \"height\" : height,\n",
    "            \"weight\" : weight,\n",
    "            \"reach\" : reach,\n",
    "            \"stance\" : stance,\n",
    "            \"dob\" : dob,\n",
    "            \"splm\" : splm,\n",
    "            \"str_acc\" : str_acc,\n",
    "            \"sapm\" : sapm,\n",
    "            \"str_def\" : str_def,\n",
    "            \"td_avg\" : td_avg,\n",
    "            \"td_avg_acc\" : td_acc,\n",
    "            \"td_def\" : td_def,\n",
    "            \"sub_avg\" : sub_avg\n",
    "        } \n",
    "        with lock:\n",
    "            fighter_detail_data.append(data_dic)\n",
    "            # print(f\"Scrapped {base_url+id}. {idx+1}/{len(all_ids)}\")\n",
    "            idx += 1\n",
    "    except:\n",
    "        print(f\"Cannot process the link {base_url+id}. Skipping this link.\")\n",
    "        return\n",
    "    \n",
    "with ThreadPoolExecutor(max_workers= MAX_THREADS) as executor:\n",
    "    results = [executor.submit(get_fighter_data, item) for item in enumerate(all_ids)]\n",
    "    for r in results:\n",
    "        r.result()\n",
    "\n",
    "df_fighter = pd.DataFrame(data= fighter_detail_data)\n",
    "df_fighter.to_csv(\"fighter_details.csv\", index = False)\n",
    "print(f\"Successfully Scrapped {len(df_fighter)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927d5ba2-0344-489e-82a3-3bb7b8bba233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "#        Scrape Fighter Profiles\n",
    "# ===========================================\n",
    "\n",
    "# Collect unique fighter IDs from both red and blue corners\n",
    "r_fighter_id = df_fight[\"r_id\"].unique()\n",
    "b_fighter_id = df_fight[\"b_id\"].unique()\n",
    "all_ids = list(set(r_fighter_id) | set(b_fighter_id))  # remove duplicates with set union\n",
    "\n",
    "base_url = \"http://ufcstats.com/fighter-details/\"\n",
    "\n",
    "def get_fighter_data(item):\n",
    "    \"\"\"\n",
    "    Scrape fighter details from UFCStats fighter profile page.\n",
    "\n",
    "    Args:\n",
    "        item (tuple): (index, fighter_id)\n",
    "\n",
    "    Side effects:\n",
    "        - Appends fighter data dictionary to the global fighter_detail_data list.\n",
    "    \"\"\"\n",
    "    idx, fighter_id = item\n",
    "    url = base_url + fighter_id\n",
    "\n",
    "    try:\n",
    "        response = session.get(url, headers=HEADER, timeout=15)\n",
    "        response.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"‚ùå Failed to retrieve {url} - {e}\")\n",
    "        return\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "\n",
    "    try:\n",
    "        # Fighter name & nickname\n",
    "        fighter_name = soup.find(\"span\", class_=\"b-content__title-highlight\").text.strip()\n",
    "        fighter_nick_name = soup.find(\"p\", class_=\"b-content__Nickname\").text.strip()\n",
    "\n",
    "        # Record: Wins - Losses - Draws\n",
    "        record_parts = (\n",
    "            soup.find(\"span\", class_=\"b-content__title-record\")\n",
    "            .text.replace(\"Record:\", \"\")\n",
    "            .strip()\n",
    "            .split(\"-\")\n",
    "        )\n",
    "        wins = int(record_parts[0].split()[0])\n",
    "        losses = int(record_parts[1].split()[0])\n",
    "        draws = int(record_parts[2].split()[0])\n",
    "\n",
    "        # Fighter details block\n",
    "        detail_list = soup.find_all(\n",
    "            \"li\", class_=\"b-list__box-list-item b-list__box-list-item_type_block\"\n",
    "        )\n",
    "\n",
    "        # Height (in cm)\n",
    "        try:\n",
    "            height_parts = (\n",
    "                detail_list[0].text.replace(\"Height:\", \"\")\n",
    "                .strip().replace(\"'\", \"\").replace('\"', \"\").split()\n",
    "            )\n",
    "            height = round((int(height_parts[0]) * 12 + int(height_parts[1])) * 2.54, 2)\n",
    "        except:\n",
    "            height = None\n",
    "\n",
    "        # Weight (lbs ‚Üí kg)\n",
    "        try:\n",
    "            weight_lbs = detail_list[1].text.replace(\"Weight:\", \"\").strip().replace(\" lbs\", \"\")\n",
    "            weight = round(float(weight_lbs) * 0.45359237, 2)\n",
    "        except:\n",
    "            weight = None\n",
    "\n",
    "        # Reach (in ‚Üí cm)\n",
    "        try:\n",
    "            reach_in = detail_list[2].text.replace(\"Reach:\", \"\").strip().replace('\"', \"\")\n",
    "            reach = round(int(reach_in) * 2.54, 2)\n",
    "        except:\n",
    "            reach = None\n",
    "\n",
    "        # Stance\n",
    "        try:\n",
    "            stance = detail_list[3].text.replace(\"STANCE:\", \"\").strip()\n",
    "            stance = stance if stance != \"\" else None\n",
    "        except:\n",
    "            stance = None\n",
    "\n",
    "        # Date of Birth\n",
    "        try:\n",
    "            dob = detail_list[4].text.replace(\"DOB:\", \"\").strip()\n",
    "            dob = dob if dob != \"--\" else None\n",
    "        except:\n",
    "            dob = None\n",
    "\n",
    "        # Performance averages\n",
    "        try:\n",
    "            splm = float(detail_list[5].text.replace(\"SLpM:\", \"\").strip())\n",
    "            str_acc = int(detail_list[6].text.replace(\"Str. Acc.:\", \"\").strip().replace(\"%\", \"\"))\n",
    "            sapm = float(detail_list[7].text.replace(\"SApM:\", \"\").strip())\n",
    "            str_def = int(detail_list[8].text.replace(\"Str. Def:\", \"\").strip().replace(\"%\", \"\"))\n",
    "            td_avg = float(detail_list[10].text.replace(\"TD Avg.:\", \"\").strip())\n",
    "            td_acc = int(detail_list[11].text.replace(\"TD Acc.:\", \"\").strip().replace(\"%\", \"\"))\n",
    "            td_def = int(detail_list[12].text.replace(\"TD Def.:\", \"\").strip().replace(\"%\", \"\"))\n",
    "            sub_avg = float(detail_list[13].text.replace(\"Sub. Avg.:\", \"\").strip())\n",
    "        except:\n",
    "            splm = str_acc = sapm = str_def = td_avg = td_acc = td_def = sub_avg = None\n",
    "\n",
    "        # Build fighter dictionary\n",
    "        data_dic = {\n",
    "            \"id\": fighter_id,\n",
    "            \"name\": fighter_name,\n",
    "            \"nick_name\": fighter_nick_name,\n",
    "            \"wins\": wins,\n",
    "            \"losses\": losses,\n",
    "            \"draws\": draws,\n",
    "            \"height\": height,\n",
    "            \"weight\": weight,\n",
    "            \"reach\": reach,\n",
    "            \"stance\": stance,\n",
    "            \"dob\": dob,\n",
    "            \"splm\": splm,\n",
    "            \"str_acc\": str_acc,\n",
    "            \"sapm\": sapm,\n",
    "            \"str_def\": str_def,\n",
    "            \"td_avg\": td_avg,\n",
    "            \"td_acc\": td_acc,\n",
    "            \"td_def\": td_def,\n",
    "            \"sub_avg\": sub_avg\n",
    "        }\n",
    "\n",
    "        # Append result safely\n",
    "        with lock:\n",
    "            fighter_detail_data.append(data_dic)\n",
    "\n",
    "        print(f\"‚úÖ Scraped fighter {idx+1}/{len(all_ids)}: {fighter_name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not parse data for {url} - {e}\")\n",
    "\n",
    "\n",
    "# ===========================================\n",
    "#      Run Fighter Scraping in Parallel\n",
    "# ===========================================\n",
    "with ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:\n",
    "    results = [executor.submit(get_fighter_data, item) for item in enumerate(all_ids)]\n",
    "    for r in results:\n",
    "        r.result()\n",
    "\n",
    "# Convert results to DataFrame and save\n",
    "df_fighter = pd.DataFrame(data=fighter_detail_data)\n",
    "df_fighter.to_csv(\"fighter_details.csv\", index=False)\n",
    "\n",
    "print(f\"üéØ Successfully scraped {len(df_fighter)} fighter profiles.\")\n",
    "df_fighter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a102e550-7d28-4a6a-af25-b618180cf8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fighter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4217229e-aec3-4e66-b7c0-9a738372db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the final data, by merging the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff98042-7d99-489c-97bf-dfa54d23f5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merger_winners = df_winner.drop(columns=['event_id']).copy() # Copying the winners data to merge later\n",
    "df_fight = df_fight.merge(right=df_merger_winners, on='fight_id') # Merging the winners data with fight data\n",
    "\n",
    "# SAME ROWS HAD DIFF MEANING SO CHANGED THE AVG DATA\n",
    "df_fighter_renamed__r = df_fighter.add_prefix('r_').drop(columns=['r_name']) # Renaming the columns for red fighter\n",
    "df_fighter_renamed__b = df_fighter.add_prefix('b_').drop(columns=['b_name']) # Renaming the columns for blue fighter\n",
    "\n",
    "df_fight = df_fight.merge(right=df_fighter_renamed__r, on='r_id') # Merging the red fighter data\n",
    "df_fight = df_fight.merge(right=df_fighter_renamed__b, on='b_id') # Merging the blue fighter data\n",
    "\n",
    "cols = df_fight.columns\n",
    "\n",
    "r_cols = [col for col in cols if col.startswith('r_')]\n",
    "b_cols = [col for col in cols if col.startswith('b_')]  \n",
    "fighter_cols = r_cols + b_cols\n",
    "\n",
    "re_ordered_cols = [\n",
    "    'event_id',\n",
    "    'event_name',\n",
    "    'date',\n",
    "    'location',\n",
    "    'fight_id',\n",
    "    'division',\n",
    "    'title_fight',\n",
    "    'method',\n",
    "    'finish_round',\n",
    "    'match_time_sec',\n",
    "    'total_rounds',\n",
    "    'referee'\n",
    "]\n",
    "re_ordered_cols += r_cols + b_cols\n",
    "re_ordered_cols += ['winner', 'winner_id']\n",
    "df_fight = df_fight[re_ordered_cols]\n",
    "\n",
    "# Converting date and dob to datetime format and then to string in the desired format\n",
    "df_fight['date'] = pd.to_datetime(df_fight['date']).dt.strftime(\"%Y/%m/%d\")\n",
    "\n",
    "df_fight['r_dob'] = pd.to_datetime(df_fight['r_dob']).dt.strftime(\"%Y/%m/%d\")\n",
    "df_fight['b_dob'] = pd.to_datetime(df_fight['b_dob']).dt.strftime(\"%Y/%m/%d\")\n",
    "\n",
    "df_fight.to_csv(\"UFC.csv\", index = False)\n",
    "df_fight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ufc_env)",
   "language": "python",
   "name": "ufc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
